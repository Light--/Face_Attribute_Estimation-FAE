{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm as tqdm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " trans = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../model/model1.pt\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "frame_width = int(cap.get(3))    \n",
    "frame_height = int(cap.get(4))\n",
    "frame_area = frame_width * frame_height\n",
    "margin = 20\n",
    "while(cap.isOpened()):\n",
    "    ret, frame1 = cap.read()\n",
    "    if ret == True:\n",
    "        frame = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "        box = detector.detect_faces(frame)\n",
    "        if len(box) == 1:\n",
    "            box = box[0]['box']\n",
    "            face = np.copy(frame[box[1]-margin:box[1]+box[3]+margin , box[0]-margin:box[0]+box[2]+margin])\n",
    "            if face.shape[0] != 0 and face.shape[1]!= 0 and face.shape[2] !=0:       \n",
    "                im = Image.fromarray(face)\n",
    "                inputs = trans(im)\n",
    "                inputs = inputs.view(1,3,224,224)\n",
    "                output = model(inputs.to(device))\n",
    "                _, preds = torch.max(output, 1)\n",
    "                if preds.cpu().numpy() == 1:\n",
    "                    text = \"OFF\"\n",
    "                else:\n",
    "                    text = \"ON\"\n",
    "                frame1 = cv2.rectangle(frame1, (box[0]-margin,box[1]-margin),(box[0]+box[2]+margin, box[1]+box[3]+margin), (255,255,255), 3)\n",
    "                cv2.putText(frame1, text , (50,50),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255) ,\n",
    "                                        thickness=2, lineType=2)\n",
    "            cv2.imshow('frame2',frame1)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
